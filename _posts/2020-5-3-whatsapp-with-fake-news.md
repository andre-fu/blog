---
layout: post
title: WhatsApp With Fake News?
---

## Introduction
As racist tendencies combine with our interconnected society, the misinformation highway is getting faster, connecting more people with fake news and misinformation. Technologies like WhatsApp that are designed to connect people together are being used to spread racist misinformation. It paints a society that’s under an equity crisis where different groups are in conflict. Some groups are using simmering racial tensions to spread fake news and gain control in a socioeconomic/governmental sense, while others are consuming misinformation and inciting racial violence. The social context of south Asian racism in Myanmar will be discussed, followed by the context of WhatsApp usage in south Asia. Then, the interconnectedness of WhatsApp & south Asian racism will be discussed and how that leads to racial violence. Finally, we’ll analyze the proposed solution by WhatsApp of forward-limiting and suggest a recommendation. Overall, this essay aims to demonstrate how racially charged misinformation via WhatsApp affects racial tensions, particularly in Myanmar, then evaluate the proposed solutions and recommend a composite solution.

## Situational Context: Racism & WhatsApp – How they go together
Our notions of racism are dominated by the euro-centric model of racism, separating ‘whites’ & ‘blacks’, but under the broad term of ‘Asian’ is a plethora of different cultures & subcultures which are often ignored. Racism in south Asia in some form has always existed, but in a post-colonial context, those racist tendencies were exacerbated by separating people into different socio-economic classes, causing an ‘us vs. them mentality’ [2]. In Myanmar racism against the Rohingya Muslim minority is being dismissed by the rest of the world. According the Lion’s Roar, a Buddhist newspaper, the Buddhist majority are afraid of the ‘dilution of the Buddhist population by the Rohingya minority, clearly defining the ‘us vs them’. [2] The UN Secretary General, Antonio Guterres, has even claimed that Myanmar has the “worst discrimination” that he has ever witnessed [3]. Even though the Rohingya comprise only 2.3% of the Myanmar population [4], the extreme views of an Ethnic Cleansing have been voiced [5]. Combining this racism with the interconnectedness of the internet specifically messaging groups where individuals can exchange their controversial ideas in private, mean that these racist sentiments bubble to the surface. WhatsApp experiences popularity in south Asia due to it’s free, global & social media features. As WhatsApp groups have high capacity, they can range from close family to entire workplace groups. As communications expert, Saanya Gulati points out, “WhatsApp is increasingly moving beyond a personal messaging platform to a form of social media” [6] . The BBC shows that in Myanmar, a “sudden explosion of internet access and a company [Facebook & WhatsApp] with trouble identifying and removing the most hateful posts” causes a “perfect storm” where WhatsApp & Facebook had a “determining role in whipping up anger against the Rohingya minority” [7].

## The Problem: Racial Violence stemming from misinformation
NPR points out that in the West, misinformation has been blamed for misleading voters, but it’s been killing people in south Asia [8] . With over 1.5 billion active WhatsApp users globally & 18 million Facebook users in Myanmar, these platforms are their only source of News & internet. In these Asian countries, millions of these Facebook & WhatsApp users don’t even know they’re using the internet [9]. This lack of separation between Facebook & the internet makes people more susceptible to fake news, as they unknowingly ingest large amounts of misinformation. By consuming misinformation on social media platforms like WhatsApp, users are being manipulated to incite racial violence [10]. WhatsApp’s parent company Facebook’s mission statement is ‘to bring people together to make the world a better place’. In a 2018 Human Rights report, they concluded that they [Facebook & WhatsApp] “weren’t doing enough to prevent the platform from being used to ferment division & incite offline violence” [11] . This disparity between their mission statement and their actions calls into question WhatsApp & Facebook’s role as the avenue for communication that millions of people use daily. This same avenue is being used to show families “videos of a child’s mutilated body”, where a voice implores the watcher to “stay vigilant” as the “kidnappers are close” [8]. The NYT, directly asserts that Facebook’s posts by Myanmar military personnel incited racial violence against the Rohingya Muslims, turning Facebook & WhatsApp into a tool ethnic cleansing [12]. Similarly, Vox claims that “the rapid spread of misinformation online often over WhatsApp also resulted in killings in countries like Myanmar” [13]. WhatsApp’s presence in South Asian countries has been contaminated by misinformation leading to racial killings, especially in Myanmar, where the Rohingya minority is being targeted.


## The Solution & Evaluation: Forward-limiting & it’s effects
WhatsApp’s main solution to curb the spread of misinformation that is inciting racial violence, is to limit the number of ‘Forwards’ a person can do, theoretically making it harder for fake news to go viral [13]. By limiting the number of people to 20 instead of the previous 250, WhatsApp is hoping to slow down the viral nature of the shocking news. After the 2018 human rights report, Alex Warofka, a Facebook executive even acknowledges “that we [Facebook & WhatsApp] should be doing more” [14]. Unfortunately, unlike Facebook with open posts, WhatsApp’s messages are encrypted meaning, that only the sender & receiver can see the messages – not even WhatsApp employees. Consequently, many of the ‘fact-checking’ groups set up by Facebook to curb misinformation don’t work in places like South Asia where WhatsApp dominates social media. WhatsApp’s main solution forward-limiting effectively falls short of creating substantive change. The forward-limit only reduces the spread of content by one order of magnitude [15] for regular news. With highly viral content (for example, claims of Muslims invading Myanmar) the forward-limit wasn’t effective in preventing spread to a large part of the network [15]. WhatsApp’s position is unique due to the encrypted nature of their messaging platform, meaning WhatsApp has restricted visibility into the messages being sent. Since these groups are all private, news travels through a chain of private groups limiting the ability of public discourse and heightening racial tensions in echo chambers. WhatsApp’s attempts at creating ‘fact-checking’ services like the “Checkpoint Tipline” are actually just research [16] [17], leaving WhatsApp with no fact-checking ability whatsoever. Socially speaking, WhatsApp’s inability to curb misinformation presents a grave danger to the framework of Truth within south Asia. As more Burmese use WhatsApp as a social media, a greater responsibility falls upon WhatsApp’s shoulders to maintain integrity and truth. Economically, WhatsApp is incentivized to keep information spreading, no matter the truth, as WhatsApp harvests data from the spread of messages. With over 1.5 billion users, WhatsApp generates an enormous amount of meta-data to sell to advertisers and Facebook [18]. Consequently, WhatsApp’s incentivization to keep people messaging about anything, combined with their inability to curb misinformation directly explains why the only real solution WhatsApp has proposed, falls short prevention of racial violence. While forward-limiting is certainly a step in the right direction, it only has a small benefit at little cost to the consumer or WhatsApp. Nonetheless it raises questions about breaches of individual freedom. By limiting the number of forwards, is WhatsApp blocking freedom of expression & speech? Facebook is under fire for removing users from their platform for violation of their terms, so by extension, WhatsApp’s forward-limit isn’t far-fetched. While negative fake-news like sensational media are getting limited by forwards, what about vital information, such as emergencies or natural disasters? Wouldn’t the dissemination of that information be important to spread as quickly as possible? Consequently, we can see that while forward-limiting seems apolitical, it has far-reaching political questions that WhatsApp has yet to answer.


## The Recommendation: Composite solution
Since WhatsApp solution falls short, a collection of small solutions would be my recommendation to curb misinformation in South Asia. Firstly, government legislation forcing WhatsApp to include fact checking services. By providing information about linked sources, consumers can become more aware of their actions, which may prevent the spread of misinformation. Secondly, an organizational policy of tech companies adhering to a code of ethics would create a culture of accountability, curbing misinformation & racial violence. Thirdly, a governmental-company-individual education campaign about the spread of misinformation would allow individuals to become more conscious of their forwarding habits.


# Conclusion

WhatsApp has been proven to negatively affect South Asian communities by spreading misinformation and fake news which incites racial violence in countries like Myanmar. Through deep-seated racism combined with the advent of a novel messaging platform-turned social media, misinformation spreads faster than wildfire. Here, we discussed how WhatsApp’s main solution of limiting forwards didn’t effectively address the challenge posed by misinformation and suggested three methods WhatsApp can use to also effectively manage misinformation on their platform.



